{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Conclusion\n",
        "author: \"Hannah Kim\"\n",
        "format:\n",
        "  html:\n",
        "    embed-resources: true\n",
        "    code-fold: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "## Goal\n",
        "\n",
        "My goal was to come up with a model that could accurately predict whether the wildlife animals would be threatened based on the climate change. Climate change could be the increased amount of greenhouse gases, global warming, ocean acidification, etc. My aim was to hopefully reach more than 75% accuracy at most. Even if any model cannot achieve this goal, I was mostly interested in learning about the models and how they work, so I considered with a relatively better accuracy.\n",
        "\n",
        "## Data used\n",
        "\n",
        "Since I was dealing with threatened species, the basic dataset I needed was a record data of the numbers of threatened species. I also needed a record data of climate change data. The data that I gathered was an OECD dataset and this was mostly consisted of categorical data. In order to perform all the models, it was best to convert the categorical values to numerical values. For text data, it was parsed from Wikipedia and News API. Then, I also vectorized the text data for Clustering and Principal Component Analysis. \n",
        "\n",
        "## Method used \n",
        "\n",
        "The course asked us to try out multiple models to see which one would come up with the most accurate predictions. We used Naive Bayes, Clustering, Decision Tress, and ARM analysis to predict on our training data. After attempting them all, I found that both the Naive Bayes and Decision Tree Classifier models performed the best for my record data, at around 70% to 75% accuracy and recall + precision also oscillating around the 75% range. However, I could not find the best model for my text data and the best accuracy I could get from the Naive Bayes model was 43% \n",
        "\n",
        "## Best model\n",
        "\n",
        "As mentioned, the best models were Naive Bayes and Decision Trees. The biggest difference between the two, in terms of setting them up, was that the decision tree can use numerical and categorical data that isn't normalized; Naive Bayes requires normalization and works best with certain types of data. To improve my results, I would likely pursue the decision tree models and explore their efficancy with both more and less variables to see what can lead to an accuracy higher than 78%. One way to try is to use a merged dataset: after merging the threatened species data and CO2 emissions data, I would like to try the decision tree classification model with this data. The other way I could think of is to find more variables, since I only had a ahandul in my dataset. Maybe, the lack of variables limited my model's ability to predict. On top of that, I would also require more data points. I thought I had enough species to train the data, but the 'threatened' species were mostly birds and they ended up having biases toward the data shown to them.\n",
        "\n",
        "## Applicability\n",
        "\n",
        "When it comes to applicability, I do think the results are not that bad, so I would love to take further steps with this project. But it definitely needs more interpretation and improvement. Although a 75% accuracy rate is respectable, I am not satisfied with this model; it still needs to be improved. Once the model is optimized, I hope its applicability would lie in some organizations such as WHO(World Health Organization) and UNEP(United Nations Environment Programme), basically anything that can use a good prediction on which species will go threatened. Furthermore, it can not only be used in predicting threatened species, but it would also be applicable for endangered species. With this in mind, I think the best for a high-accuracy model would be the one that's much more complicated than the methods I attempted.\n",
        "\n",
        "## Final thoughts\n",
        "\n",
        "In my project introduction, I mentioned that my real goal for this project is to learn about different models and understand what each one of them is doing. Having gone through the semester, I can now confidently explain what each model is doing and I have a proper understanding of what's going on behind the scenes. So, in terms of my real goal, I have achieved what I intended. In terms of the best model I was able to create, while I am somewhat satisfied with the outcomes I have achieved which was 75% of accuracy performance, there were some aspects that left me dissatisfied. That being said, I was not satistied with the skewed results; the features' weight on the prediction was biased. Also, I think the results from Decision Tree Regressor model could have been better. I used a merged dataset, but the merged features were not effective when predicting the model. So, I am expecting the results will be less biased if I could add more effective features to the dataset. Additionally, I think the accuracy score for text data prediction in some models such as Clustering and Naive Bayes should be improved. So I will go on experiment to find the optimal model, and once I find it, I would be interested in exploring its weights and studying which variables had the highest weight on the prediction; I would like to know if the variables expected to be important would actually be of importance or if other, less expected variables, have a surprisingly high weight on the predictions.\n",
        "\n",
        "## Future work\n",
        "\n",
        "As mentioned, the future work will include some more feature selection and finding the optimal model that will give us more than 78% of accuracy. For feature selection, I will gather more data in order to even out the features' weight on the prediction and in terms of finding the optimal model, it will probably be similar to what I have used for this project but will be more focused on Clustering and Decision Tree Regression since these two methods needed improvement the most. This would be prioritized among all the future works, and once it is done, I might focus on Association Rule Mining. I have done this process on my text data, but I would also like to apply the rule mining method; apriori algorithm on my record data. Regarding the topic of my project, now that I have explored the threatened species data I am more than happy to move onto my next topic: 'What effects does the deforestation have on both terrestrial and marine animals?' and 'What is the change in the habitat of marine animal species in Southern seas of S.Korea and Australia due to global warming?,' and since the second topic is more concrete than the first one, I will probably refer to the first question and work on the second one. The country in the question is changeable based on the dataset that I will gather. \n",
        "\n",
        "# Summary of my work\n",
        "\n",
        "## Data Gathering and Cleaning\n",
        "\n",
        "I have gathered two datasets related to threatened species and climate change; CO2 emissions. My primary resource was the OECD website, which provided access to a developer API. It was challenging to use the API and parse the JSON file since I was not that familiar with JSON, so I had to use a .csv file in order to move onto the next step. But eventually, I succeeded using the SDMX-JSON API to extrat the authentic data. Regarding data cleaning, I had to clean the data several times for each tab because each tab needed a new form of data. At first, I removed all the unnecessary columns and checked whether it contains any null values. Then for the Naive Bayes, I had to use one hot encoding to convert all the categorical values to numerical values, and had to create a tf-idf matrix for my text data in PCA tab. Also, in decision tree tab, I had to merge the two datasets for better results. \n",
        "\n",
        "## Data Exploration\n",
        "\n",
        "Data Exploration gave me more understanding in my data. Initially, I thought the most threatened species overall would be mammals, but it turns out that birds are the most threatened species. I have not mentioned in this project, but I was curious of the reason why the most threatened species is birds and would like to add on to my project list. Regarding the CO2 emission dataset, we can conclude that the amount of CO2 emissions had been increasing for Australia and Korea but decreased for Spain. So I thought it would be interesting to compare the results based on countries. \n",
        "\n",
        "## Na√Øve Bayes\n",
        "\n",
        "As mentioned above, Naive Bayes method was the best model for predicting my data. I wanted to focus on only the threatened species, so I converted all the non-threatened species data to zeros and converted the threatened species to ones after further data cleaning and one hot encoding. Then I was able to use the Naive Bayes model since my dataset now contains only numerical values. As expected, we got approximately 75% of accuracy and I am satistied with this result. \n",
        "\n",
        "## Dimensionality Reduction\n",
        "\n",
        "Although I went through all the methods in my project, I need further understanding of dimensionality reduction. However, the conclusion of PCA and t-SNE was interesting. PCA is a dimensionality reduction method for supervised learning and t-SNE is for un-supervised learning. So initailly I thought PCA would work best for my dataset since it contains categorical data, but it turns out that PCA worked best for my text data but not for my record data. On the other hand, t-SNE workded best for my record data and not for my text data. From this perspective, it seems like my record data does not have a linear relationship because t-SNE gave me more meaningful results than PCA. \n",
        "\n",
        "## Clustering\n",
        "\n",
        "Unfortunately, clustering method; K-means, DBSCAN, and hierarchical clustering did not work well for my data. I worked with my record data first, and could not get a satisfying result, so I tried to work with the vectorized text data as well and also tried an alternative method such as Mean Shift, but unluckily, clustering was not a best model for neither of them. I think the reason of this is because my dataset contained a lot of categorical data. However, I think it was a good overview of knowing the optimal number of clusters for both my record data and text data. \n",
        "\n",
        "## Decision Trees\n",
        "\n",
        "For this tab, I used the same dataset in the Naive Bayes process for Decision Tree Classifier and used a merged dataset for Decision Tree Regressor. The classifier method's result was rather meaningful than the regressor method, even though I thought the merged dataset would give me more meaningful results. The optimal tree structure for my dataset is as follows: maximum depth should be 7 or 8, maximum number of leaves shoudl be 4 and the maximum number of samples required to splitt the internal nodes should be 2. Also, this is the point where I found the feature's weight was skewed. Including deep-diving into RMSE and Regressor method, these improvement are on my future work list. \n",
        "\n",
        "## ARM\n",
        "\n",
        "For Association Rule Mining, I wanted to apply the method on both my record data and text data. This method worked for my text data, but unfortunately it did not work for my record data. I would like to take further process on this and find out if there is any way to apply ARM on categorical data. I have searched for some resources and I was able to find an information that ARM is applicable on categorical data. So this will be on my future work list. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
